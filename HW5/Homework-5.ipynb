{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "**Total Points: 5**\n",
    "\n",
    "**Instructions:**\n",
    "1. Complete parts 1 through 5, filling in code or responses where marked with `# YOUR CODE HERE` or `# YOUR ANALYSIS HERE`.\n",
    "2. The libraries you need, in the order you need them, have already been coded. Do not import additional libraries or move import commands.\n",
    "3. When finished, run the full notebook by selecting <b>Kernel > Restart & Run All</b>. </li>\n",
    "4. Submit this completed notebook file to <b>NYU Classes</b>. </li>\n",
    "\n",
    "In this assignment you will create a Nearest Neighbor classifier, train it, and test it. The goal of your classifier to predict whether the input audio contains a \"talking\" voice or a \"singing\" voice based on the training data. This assignment contains a subfolder called `audio` which has multiple short audio files from the dataset *VocalSet: A Singing Voice Dataset*.\n",
    "\n",
    "**Grading:** Each part is worth 1 point.\n",
    "\n",
    "**Important Note**: The way you implement the code in your work for each assignment is entirely up to you. There are often many ways to solve a particular problem, so use whatever method works for you, including testing different parameter values. The only requirement is that you follow the instructions, which may prohibit or require certain libraries or commands.\n",
    "\n",
    "Refer to https://scikit-learn.org/ for implementation instructions and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from librosa import feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imported for plotting/testing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Prepare Data\n",
    "Create a function `prepare_data()` that will take an array of files and prepare them for a nearest neighbor machine learning task. This function should:\n",
    "1. Take the input array of audio files for one class (arrays are provided in Part 2),\n",
    "2. Concatenate the audio into one long audio file,\n",
    "3. Generate an `mfccs` matrix from this one audio file (use `Librosa.feature.mfcc()` for this),\n",
    "4. Remove the first MFCC.\n",
    "5. Generate a `label` that is an array of the label number the same size as the number of samples (each set of MFCCs should have the same corresponding label),\n",
    "6. Output both `mfccs` and `labels` from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(audiofiles, label):\n",
    "    \n",
    "    \"\"\" Prepare data for Nearest Neighbor classification\n",
    "        Hint: When generating MFCCs, you can use Librosa's default\n",
    "        or experiment. 13 is a common number of MFCC coefficients to retain.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    audiofiles: np.array\n",
    "        array of input audio files\n",
    "    \n",
    "    label: int\n",
    "        The label to give these audio features\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    mfccs: np.array\n",
    "        mfcc feature set\n",
    "    labels: np.array\n",
    "        labels for feature set\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # -------------------------------------------------- #\n",
    "    # Note: the mfccs are of size ( features * samples ) #\n",
    "    # The labels are outputted as a zero dimension array #\n",
    "    # of length ( samples ). I will match them in the    #\n",
    "    # next part                                          #\n",
    "    # -------------------------------------------------- #\n",
    "    \n",
    "    # Extracting data from files and combining them to one array\n",
    "    combined_audio_file = np.array([])\n",
    "    \n",
    "    for file in audiofiles:\n",
    "        data, sr = librosa.load(file)\n",
    "        assert sr == 22050\n",
    "        combined_audio_file = np.append(combined_audio_file, data)\n",
    "\n",
    "    # Generate MFCC matrix for the combined audio file\n",
    "    mfcc = librosa.feature.mfcc(combined_audio_file, n_mfcc = 13)\n",
    "    \n",
    "    # Removing the bottom row of mfccs\n",
    "    mfcc = mfcc[ 1 : , : ]\n",
    "    \n",
    "    # Generating the label array\n",
    "    labels = [ label for i in range(mfcc.shape[1]) ]\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return mfcc, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Set Up the Experiment\n",
    "\n",
    "Using `prepare_data()` prepare your Nearest Neighbor classification experiment as follows:\n",
    "\n",
    "- Run `prepare_data()` twice, once using the files in array `talking_files` and once using `singing_files`,\n",
    "- Append the feature vectors and label vectors so that you have two data objects; one with all features and one with all labels.\n",
    "- Take care that the objects' dimensions match and that `label[n]` corresponds to `feature_vector[n]`.\n",
    "\n",
    "**Hint:** Rows should be samples, and columns should be features. Python is row-centric, so rows come first. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4924, 12)\n",
      "(4924,)\n"
     ]
    }
   ],
   "source": [
    "# Use singing_files and talking_files for Part 2; the vibrato_files is for Part 5\n",
    "singing_files = np.array(['audio/f1_row_straight.wav','audio/f2_row_straight.wav','audio/m1_row_straight.wav','audio/m2_row_straight.wav'])\n",
    "talking_files = np.array(['audio/f1_row_spoken.wav','audio/f2_row_spoken.wav','audio/m1_row_spoken.wav','audio/m2_row_spoken.wav'])\n",
    "vibrato_files = np.array(['audio/f1_row_vibrato.wav','audio/f2_row_vibrato.wav','audio/m1_row_vibrato.wav','audio/m2_row_vibrato.wav'])\n",
    "\n",
    "singing_mfcc, singing_labels = prepare_data( singing_files, \"S\")\n",
    "talking_mfcc, talking_labels = prepare_data( talking_files, \"T\")\n",
    "\n",
    "feature_vector = np.append(singing_mfcc, talking_mfcc, axis = 1).T\n",
    "labels = np.append(singing_labels, talking_labels)\n",
    "\n",
    "print(feature_vector.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Find the Nearest Neighbor\n",
    "Create a function `find_nearest_neighbor()` without using scikit-learn (except for the function in step #1), You may use a process of your choice. One way to write the code is as follows:\n",
    "\n",
    "1. Separate your data into training and testing sets (use scikit-learn's `train_test_split()` for this - start with a test_size of 0.1 (10%).\n",
    "2. For the first feature vector in the test set, find the Euclidean distance between it and every vector in the training set, keeping track of the distances in an array.\n",
    "3. When finished, use `np.argmin()` to find the index of the smallest distance. That is the Nearest Neighbor of that first test feature vector.\n",
    "4. If the label of the training vector with the lowest distance is the same as the label of the test vector, then it is a match. Otherwise it is wrong.\n",
    "5. Repeat steps 2-4 for every test vector.\n",
    "8. When finished, the program should output the number of correct vs incorrect matches.\n",
    "9. Run the program multiple times, making sure that the test/training sets are random each time. You can also adjust the size of the test set.\n",
    "\n",
    "**Note that this implementation will take a while to run.** Also note that, since this function is only finding the nearest neighbor (and not k-neighbors), there is no validation set.\n",
    "\n",
    "\n",
    "The equation for finding the Euclidean distance between two N-dimentional vectors $p$ and $q$ is:\n",
    "\n",
    "$$d(p,q) = \\sqrt{ \\sum_{n=0}^{N-1}{ (p_n - q_n)^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([455,  38])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_nearest_neighbor(data, labels, test_size):\n",
    "    \n",
    "    \"\"\" Perform Nearest Neighbor classification\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    data: np.array\n",
    "        feature set\n",
    "    \n",
    "    labels: np.array\n",
    "        true labels for the features\n",
    "        \n",
    "    test_size: float\n",
    "        Between 0 and 1, the amount of data set aside for testing\n",
    "          \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    [correct, incorrect]: np.array\n",
    "        the numer of correct and incorrect results\n",
    "\n",
    "    \"\"\"\n",
    "    # Separate the data to training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, \n",
    "                                                        test_size = test_size )\n",
    "    \n",
    "    # Finding the nearest label for every vector in test set\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range( len(X_test) ) :\n",
    "        test_vector = X_test[i]\n",
    "        temp_distances = []\n",
    "        for train_vector in X_train:\n",
    "            distance = np.sum( (test_vector - train_vector)**2 )**0.5\n",
    "            temp_distances.append(distance)\n",
    "        min_dist_index = np.argmin( temp_distances )\n",
    "        \n",
    "        if y_train[min_dist_index] == y_test[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    \n",
    "    return np.array([correct, incorrect])\n",
    "\n",
    "find_nearest_neighbor(feature_vector, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Cross Validation and Confusion Matrix\n",
    "Using Scikit-Learn, set up a Nearest Neighbor experiment using k-fold cross validation and output a confusion matrix. All the sklearn modules you need have been imported for you.\n",
    "1. Break the data into training and testing sets (as before).\n",
    "2. Create a new classifier by using neighbors.KNeighborsClassifier()\n",
    "3. \"Fit\" the training data to the model (this basically means \"train the model\").\n",
    "4. Use `cross_val_scores()` on the classifier, setting cv=10 and output the scores.\n",
    "5. Get predictions using `predict() with the test data.\n",
    "6. Print the confusion matrix using the true vs. predicted labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores:  [0.8        0.86       0.82       0.79591837 0.79591837 0.7755102\n",
      " 0.73469388 0.85714286 0.79591837 0.85714286]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[256,  13],\n",
       "       [ 18, 206]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOU CAN USE THESE LIBRARIES\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Break the data into training and testing sets (as before).\n",
    "X_train, X_test, y_train, y_test = train_test_split( feature_vector, \n",
    "                                                    labels, \n",
    "                                                    test_size = 0.1)\n",
    "\n",
    "# Create a new classifier by using neighbors.KNeighborsClassifier()\n",
    "KN_classifier = neighbors.KNeighborsClassifier( n_neighbors = 3 )\n",
    "\n",
    "# \"Fit\" the training data to the model.\n",
    "KN_classifier.fit( X_train, y_train )\n",
    "\n",
    "# Use cross_val_scores() on the classifier, setting cv=10 and output the scores.\n",
    "cv_score = cross_val_score( KN_classifier, X_test, y_test, cv = 10 )\n",
    "print(\"cross validation scores: \", cv_score)\n",
    "\n",
    "# Get predictions using `predict() with the test data.\n",
    "predictions = KN_classifier.predict( X_test )\n",
    "\n",
    "# Print the confusion matrix using the true vs. predicted labels.\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Analysis\n",
    "How would you characterize your overall results? Does your classifier work better or worse than `sklearn`? Or are they similar?\n",
    "\n",
    "There is a third class of audio included with this assignment, `vibrato_files`,  which contains singers using vibrato. Add this data to your full dataset and give it a unique label. Then run the whole test again (using `sklearn` - no need to run your code from Part 3 again). \n",
    "1. Perform 10-fold cross validation again. How so the results compare now that you have 3 classes.\n",
    "2. Generate a confusion matrix again. How does that data compare?\n",
    "\n",
    "(OPTIONAL) MFCC deltas ($\\Delta$) may (or may not) improve the overall results. In addition to using the MFCCs generated by the MFCC function, append to each vector an MFCC difference such that, for each MFCC feature vector $f[m]$ at time index $m$, $\\Delta f[m] = f[m] - f[m-1]$. This will double the amount of features per vector. Report on your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding vibrato files to the set\n",
    "singing_files = np.array(['audio/f1_row_straight.wav','audio/f2_row_straight.wav','audio/m1_row_straight.wav','audio/m2_row_straight.wav'])\n",
    "talking_files = np.array(['audio/f1_row_spoken.wav','audio/f2_row_spoken.wav','audio/m1_row_spoken.wav','audio/m2_row_spoken.wav'])\n",
    "vibrato_files = np.array(['audio/f1_row_vibrato.wav','audio/f2_row_vibrato.wav','audio/m1_row_vibrato.wav','audio/m2_row_vibrato.wav'])\n",
    "\n",
    "singing_mfcc, singing_labels = prepare_data( singing_files, \"S\")\n",
    "talking_mfcc, talking_labels = prepare_data( talking_files, \"T\")\n",
    "vibrato_mfcc, vibrato_labels = prepare_data( vibrato_files, \"V\")\n",
    "\n",
    "feature_vector = np.hstack((singing_mfcc, talking_mfcc, vibrato_mfcc)).T\n",
    "labels = np.hstack((singing_labels, talking_labels, vibrato_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7575, 12)\n",
      "(7575,)\n"
     ]
    }
   ],
   "source": [
    "print(feature_vector.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation scores:  [0.64473684 0.68421053 0.67105263 0.73684211 0.69736842 0.69736842\n",
      " 0.76315789 0.61842105 0.61333333 0.52      ]\n",
      "\n",
      "\n",
      "Confusion Matrix Index:\n",
      "Singing, Talking, Vibrato\n",
      "[[247  10  14]\n",
      " [ 26 179   8]\n",
      " [ 57  11 206]]\n"
     ]
    }
   ],
   "source": [
    "# Break the data into training and testing sets (as before).\n",
    "X_train, X_test, y_train, y_test = train_test_split( feature_vector, \n",
    "                                                    labels, \n",
    "                                                    test_size = 0.1)\n",
    "\n",
    "# Create a new classifier by using neighbors.KNeighborsClassifier()\n",
    "KN_classifier = neighbors.KNeighborsClassifier( n_neighbors = 4 )\n",
    "\n",
    "# \"Fit\" the training data to the model.\n",
    "KN_classifier.fit( X_train, y_train )\n",
    "\n",
    "# Use cross_val_scores() on the classifier, setting cv=10 and output the scores.\n",
    "cv_score = cross_val_score( KN_classifier, X_test, y_test, cv = 10 )\n",
    "print(\"cross validation scores: \", cv_score)\n",
    "\n",
    "# Get predictions using `predict() with the test data.\n",
    "predictions = KN_classifier.predict( X_test )\n",
    "\n",
    "# Print the confusion matrix using the true vs. predicted labels.\n",
    "confusion_matrix_ = confusion_matrix(y_test, predictions)\n",
    "print(\"\\n\\nConfusion Matrix Index:\\nSinging, Talking, Vibrato\")\n",
    "print(confusion_matrix_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``\n",
    "It's clear from the confusion matrix that the current model is doing quite well predicting Singing and Talking samples. However, it doesn't do quite well differentiating Vibrato with Singing samples, as seen in the bottom left and top right position of the confusion matrix. Very often it confuses Vibrato samples with Singing samples (Bottom Left)\n",
    "``"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
